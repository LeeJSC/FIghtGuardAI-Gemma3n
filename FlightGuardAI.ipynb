{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vUHrMtmYeoL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjySsv9eYfkN"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Install latest transformers for Gemma 3N\n",
        "!pip install --no-deps --upgrade timm # Only for Gemma 3N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Xbb0cuLzwgf"
      },
      "outputs": [],
      "source": [
        "from unsloth import FastModel\n",
        "import torch\n",
        "\n",
        "\"\"\"\n",
        "fourbit_models = [\n",
        "    # 4bit dynamic quants for superior accuracy and low memory use\n",
        "    \"unsloth/gemma-3n-E4B-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3n-E2B-it-unsloth-bnb-4bit\",\n",
        "    # Pretrained models\n",
        "    \"unsloth/gemma-3n-E4B-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3n-E2B-unsloth-bnb-4bit\",\n",
        "\n",
        "    # Other Gemma 3 quants\n",
        "    \"unsloth/gemma-3-1b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-12b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-27b-it-unsloth-bnb-4bit\",\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a897733"
      },
      "outputs": [],
      "source": [
        "\n",
        "import json\n",
        "import csv\n",
        "import os\n",
        "from datetime import timedelta\n",
        "from typing import List, Tuple\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23b4ed13"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_chunks(audio_length_sec: int, window_size=15, overlap=5) -> List[Tuple[int, int, str]]:\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < audio_length_sec:\n",
        "        end = min(start + window_size, audio_length_sec)\n",
        "        chunks.append((start, end, f\"chunk_{start:04d}_{end:04d}.mp3\"))\n",
        "        start += (window_size - overlap)\n",
        "    return chunks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff0e1618"
      },
      "outputs": [],
      "source": [
        "\n",
        "def prune_summary(summary_list, max_entries=50):\n",
        "    if len(summary_list) <= max_entries:\n",
        "        return summary_list\n",
        "    condensed_note = \"Earlier: \" + \"; \".join(summary_list[:len(summary_list) - max_entries + 1])\n",
        "    return [condensed_note] + summary_list[-(max_entries - 1):]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31cad24c"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "def inference_function(model, tokenizer, chunk_path, summary_so_far, chunk_start, chunk_end):\n",
        "    summary_text = \"\\n\".join(summary_so_far) if summary_so_far else \"None so far.\"\n",
        "    prompt = f\"\"\"\n",
        "You are analysing a 15-second cockpit audio segment in the context of all important events so far.\n",
        "\n",
        "Previous important events & tone trends:\n",
        "{summary_text}\n",
        "\n",
        "Current audio segment start time: {chunk_start}\n",
        "Current audio segment end time: {chunk_end}\n",
        "\n",
        "Your tasks:\n",
        "1. Transcribe the spoken content of the current audio accurately.\n",
        "2. Detect tone/emotion in this segment (e.g., calm, panicked, urgent, frustrated, angry, distressed).\n",
        "3. Assess risk level using both:\n",
        "   - The current 15-second audio segment.\n",
        "   - The summary of previous important events and tone trends.\n",
        "4. Explain the reasoning for your risk assessment, referring to both current and past context where relevant.\n",
        "5. Keep the reasoning short but precise.\n",
        "6. Do not include any text outside of the JSON structure.\n",
        "\n",
        "Respond in **valid JSON** exactly in this format:\n",
        "{{\n",
        "  \"chunk_start\": \"HH:MM:SS\",\n",
        "  \"chunk_end\": \"HH:MM:SS\",\n",
        "  \"transcript\": \"<full transcription>\",\n",
        "  \"tone\": {{\n",
        "    \"label\": \"<tone label>\",\n",
        "    \"confidence\": <0.0 to 1.0>\n",
        "  }},\n",
        "  \"risk\": {{\n",
        "    \"level\": \"<HIGH | MEDIUM | LOW>\",\n",
        "    \"reason\": \"<short explanation>\"\n",
        "  }},\n",
        "  \"updated_summary\": \"<brief important events from this segment to append to summary>\"\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "    messages = [{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"audio\", \"audio\": chunk_path},\n",
        "            {\"type\": \"text\", \"text\": prompt}\n",
        "        ]\n",
        "    }]\n",
        "\n",
        "    response = model.generate(\n",
        "        **tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            add_generation_prompt=True,\n",
        "            tokenize=True,\n",
        "            return_dict=True,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(\"cuda\"),\n",
        "        max_new_tokens=512,\n",
        "        temperature=1.0,\n",
        "        top_p=0.95,\n",
        "        top_k=64\n",
        "    )\n",
        "\n",
        "    decoded = tokenizer.batch_decode(response)[0]\n",
        "    json_str=decoded.split(\"<start_of_turn>model\\n```json\\n\")[1].split(\"\\n```<end_of_turn>\")[0]\n",
        "\n",
        "    print(\"=== Extracted JSON ===\")\n",
        "    print(json_str)\n",
        "    print(\"=====================\")\n",
        "\n",
        "    try:\n",
        "        return json.loads(json_str)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"⚠️ JSON parsing failed:\", e)\n",
        "        return {\n",
        "            \"chunk_start\": chunk_start,\n",
        "            \"chunk_end\": chunk_end,\n",
        "            \"transcript\": \"\",\n",
        "            \"tone\": {\"label\": \"\", \"confidence\": 0.0},\n",
        "            \"risk\": {\"level\": \"LOW\", \"reason\": \"Parsing failed\"},\n",
        "            \"updated_summary\": \"[Parsing failed]\"\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ece29fd9"
      },
      "outputs": [],
      "source": [
        "\n",
        "def starter_function(chunk, summary_so_far_list, all_results, model=None, tokenizer=None):\n",
        "    if model is None or tokenizer is None:\n",
        "        print(\"⚠️ Model/Tokenizer not passed in — loading inside starter_function()\")\n",
        "        model, tokenizer = load_model_and_tokenizer()\n",
        "\n",
        "    chunk_start_sec, chunk_end_sec, audio_path = chunk\n",
        "    chunk_start_str = str(timedelta(seconds=chunk_start_sec))\n",
        "    chunk_end_str = str(timedelta(seconds=chunk_end_sec))\n",
        "\n",
        "    result_json = inference_function(model, tokenizer, audio_path, summary_so_far_list, chunk_start_str, chunk_end_str)\n",
        "\n",
        "    all_results.append(result_json)\n",
        "    summary_so_far_list.append(result_json[\"updated_summary\"])\n",
        "    summary_so_far_list = prune_summary(summary_so_far_list)\n",
        "    return all_results, summary_so_far_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d2246f3"
      },
      "outputs": [],
      "source": [
        "\n",
        "def merge_high_risk(results):\n",
        "    merged = []\n",
        "    current_event = None\n",
        "    for r in results:\n",
        "        if r[\"risk\"][\"level\"] == \"HIGH\":\n",
        "            if not current_event:\n",
        "                current_event = {\n",
        "                    \"start\": r[\"chunk_start\"],\n",
        "                    \"end\": r[\"chunk_end\"],\n",
        "                    \"reason\": [r[\"risk\"][\"reason\"]],\n",
        "                    \"tone\": [r[\"tone\"][\"label\"]]\n",
        "                }\n",
        "            else:\n",
        "                current_event[\"end\"] = r[\"chunk_end\"]\n",
        "                current_event[\"reason\"].append(r[\"risk\"][\"reason\"])\n",
        "                current_event[\"tone\"].append(r[\"tone\"][\"label\"])\n",
        "        else:\n",
        "            if current_event:\n",
        "                merged.append(current_event)\n",
        "                current_event = None\n",
        "    if current_event:\n",
        "        merged.append(current_event)\n",
        "    return merged\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29a59388"
      },
      "outputs": [],
      "source": [
        "\n",
        "def save_results(results, merged_events=None):\n",
        "    with open(\"results.csv\", \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"Start\", \"End\", \"Transcript\", \"Tone\", \"Confidence\", \"Risk\", \"Reason\"])\n",
        "        for r in results:\n",
        "            writer.writerow([\n",
        "                r[\"chunk_start\"], r[\"chunk_end\"],\n",
        "                r[\"transcript\"], r[\"tone\"][\"label\"],\n",
        "                r[\"tone\"][\"confidence\"], r[\"risk\"][\"level\"],\n",
        "                r[\"risk\"][\"reason\"]\n",
        "            ])\n",
        "\n",
        "    if merged_events:\n",
        "        with open(\"high_risk_events.csv\", \"w\", newline=\"\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([\"Start\", \"End\", \"Tones\", \"Reasons\"])\n",
        "            for e in merged_events:\n",
        "                writer.writerow([\n",
        "                    e[\"start\"], e[\"end\"],\n",
        "                    \", \".join(set(e[\"tone\"])),\n",
        "                    \"; \".join(set(e[\"reason\"]))\n",
        "                ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35cabcc2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_model_and_tokenizer():\n",
        "    from unsloth import FastModel\n",
        "    print(\"Loading Gemma3N model and tokenizer...\")\n",
        "    model, tokenizer = FastModel.from_pretrained(\n",
        "        model_name = \"unsloth/gemma-3n-E4B-it-unsloth-bnb-4bit\",\n",
        "        dtype = None,\n",
        "        max_seq_length = 2048,\n",
        "        load_in_4bit = True,\n",
        "        full_finetuning = False,\n",
        "    )\n",
        "    print(\"Model and tokenizer loaded.\")\n",
        "    return model, tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69761abe"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def split_audio(file_path, chunk_len=15*1000, overlap=5*1000):\n",
        "    audio = AudioSegment.from_file(file_path)\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(audio):\n",
        "        end = min(start + chunk_len, len(audio))\n",
        "        chunk_audio = audio[start:end]\n",
        "        chunk_path = f\"chunk_{start//1000:04d}_{end//1000:04d}.mp3\"\n",
        "        chunk_audio.export(chunk_path, format=\"mp3\")\n",
        "        chunks.append((start//1000, end//1000, chunk_path))\n",
        "        start += (chunk_len - overlap)\n",
        "    return chunks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d25a5750"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_risk_timeline(results, merged_events):\n",
        "    # Convert HH:MM:SS to seconds for plotting\n",
        "    def time_to_sec(t):\n",
        "        parts = list(map(int, t.split(\":\")))\n",
        "        return parts[0]*3600 + parts[1]*60 + parts[2]\n",
        "\n",
        "    times = [time_to_sec(r[\"chunk_start\"]) for r in results]\n",
        "    risk_levels = [3 if r[\"risk\"][\"level\"]==\"HIGH\" else\n",
        "                   2 if r[\"risk\"][\"level\"]==\"MEDIUM\" else 1 for r in results]\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.plot(times, risk_levels, marker='o', label=\"Risk Level\", linewidth=1)\n",
        "\n",
        "    for event in merged_events:\n",
        "        plt.axvspan(time_to_sec(event[\"start\"]), time_to_sec(event[\"end\"]), color=\"red\", alpha=0.3)\n",
        "\n",
        "    plt.yticks([1, 2, 3], [\"LOW\", \"MEDIUM\", \"HIGH\"])\n",
        "    plt.xlabel(\"Time (seconds)\")\n",
        "    plt.ylabel(\"Risk Level\")\n",
        "    plt.title(\"Risk Timeline\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"risk_timeline.png\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e861d7ee"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def simulator(audio_file, realtime_delay=False, model=None,tokenizer=None):\n",
        "    chunks = split_audio(audio_file, chunk_len=15*1000, overlap=5*1000)\n",
        "    if not(model and tokenizer):\n",
        "        model, tokenizer = load_model_and_tokenizer()\n",
        "    summary_so_far_list = []\n",
        "    all_results = []\n",
        "\n",
        "    for chunk in chunks:\n",
        "        all_results, summary_so_far_list = starter_function(\n",
        "            chunk, summary_so_far_list, all_results, model, tokenizer\n",
        "        )\n",
        "        if realtime_delay:\n",
        "            time.sleep(1)  # Change to 15 for real-time pacing\n",
        "\n",
        "    merged_events = merge_high_risk(all_results)\n",
        "    save_results(all_results, merged_events)\n",
        "    plot_risk_timeline(all_results, merged_events)\n",
        "\n",
        "    print(f\"Processed {len(all_results)} chunks and {len(merged_events)} high-risk events.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HfcRZKbid4M"
      },
      "outputs": [],
      "source": [
        "model, tokenizer = load_model_and_tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkzqqG8rY352"
      },
      "outputs": [],
      "source": [
        "simulator(\"8501_full audio.mov\",model=model,tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simulator(\"Alitalia final.mp3\",model=model,tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "lOy1eSffeJoA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "q2-ddk0CWeTA",
        "wZrmFRZpZtGf",
        "L15JuAmmaOkB"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}